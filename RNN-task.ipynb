{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Abagael', ' Claresta', ' Glory', ' Liliane', ' Prissie', ' Geeta', ' Giovanne', ' Piggy']\n"
     ]
    }
   ],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]\n",
    "print(names[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe2481733c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n",
      "['b', 'X', 'j', ' ', 'C', 'Q', 'g', 'i', 'x', 'G', 'z', 'm', 'y', 'Y', 'n', 'L', 'o', 'e', 'N', 's', 'V', 't', 'p', '-', 'D', 'd', 'B', 'l', 'F', 'u', 'E', 'H', 'R', 'S', 'r', 'k', 'O', 'M', 'U', \"'\", 'a', 'q', 'h', 'T', 'w', 'P', 'v', 'Z', 'J', 'I', 'c', 'A', 'f', 'K', 'W', '#']\n"
     ]
    }
   ],
   "source": [
    "tokens = set() ### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "for name in names:\n",
    "    for char in name:\n",
    "        tokens.add(char)\n",
    "\n",
    "tokens = list(tokens)\n",
    "tokens.append(pad_token)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 0, 'X': 1, 'j': 2, ' ': 3, 'C': 4, 'Q': 5, 'g': 6, 'i': 7, 'x': 8, 'G': 9, 'z': 10, 'm': 11, 'y': 12, 'Y': 13, 'n': 14, 'L': 15, 'o': 16, 'e': 17, 'N': 18, 's': 19, 'V': 20, 't': 21, 'p': 22, '-': 23, 'D': 24, 'd': 25, 'B': 26, 'l': 27, 'F': 28, 'u': 29, 'E': 30, 'H': 31, 'R': 32, 'S': 33, 'r': 34, 'k': 35, 'O': 36, 'M': 37, 'U': 38, \"'\": 39, 'a': 40, 'q': 41, 'h': 42, 'T': 43, 'w': 44, 'P': 45, 'v': 46, 'Z': 47, 'J': 48, 'I': 49, 'c': 50, 'A': 51, 'f': 52, 'K': 53, 'W': 54, '#': 55}\n"
     ]
    }
   ],
   "source": [
    "token_to_id = {} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "for i,t in enumerate(tokens):\n",
    "    token_to_id[t] = i\n",
    "print(token_to_id)\n",
    "#token_to_id.append(pad_token)\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[ 3 51  0 40  6 40 17 27 55]\n",
      " [ 3  9 27 16 34 12 55 55 55]\n",
      " [ 3 45 34  7 19 19  7 17 55]\n",
      " [ 3  9  7 16 46 40 14 14 17]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation = 'tanh') ### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation = 'softmax')### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate\n",
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = Concatenate()([x_t_emb,h_t]) ### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = -tf.reduce_mean(answers_matrix*tf.log(predictions_matrix)) ### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe1f1bb5a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "#s = keras.backend.get_session()\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Myorie\n",
      " Bovit\n",
      " Manuto\n",
      " Martande\n",
      " Dalka\n",
      " Rie\n",
      " Anerdo\n",
      " Celly\n",
      " yoghiy\n",
      " Suwig\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpai\n",
      " Trumpe\n",
      " Trumpa\n",
      " Trumpyu\n",
      " Trumpen\n",
      " Trumpite\n",
      " Trumpy\n",
      " Trumpaerma\n",
      " Trumpao\n",
      " Trumplle\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"CfZoo9l5CLYzkxwp\" ### YOUR TOKEN HERE ###\n",
    "COURSERA_EMAIL = \"udaygurugubelli@gmail.com\"### YOUR EMAIL HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cead3ee0eb4645f79ad698ccf7fba146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
